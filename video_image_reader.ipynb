{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T13:07:29.889467Z",
     "start_time": "2025-11-05T13:07:19.236003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from llama_index.core.agent import AgentOutput\n",
    "from llama_index.core.async_utils import asyncio_run\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from typing import List\n",
    "from ultralytics.engine.results import Results\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Settings, SimpleDirectoryReader\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Initialize Ollama LLM\n",
    "    llm = Ollama(model=\"llama3.1:latest\", request_timeout=120.0)  # Adjust model and timeout as needed\n",
    "    # Set as global LLM in LlamaIndex Settings\n",
    "    Settings.llm = llm\n",
    "    llm = Ollama(\n",
    "        model=\"llama3.1:latest\",\n",
    "        base_url=\"http://localhost:11434/\",\n",
    "        request_timeout=360.0,\n",
    "        # Manually set the context window to limit memory usage\n",
    "        context_window=8000,\n",
    "    )\n",
    "    yolo_model = YOLO('predict/best.pt')\n",
    "\n",
    "    def analyse_image_ppe_violation() -> str:\n",
    "        image_directory_path = \"./test\"\n",
    "        image_documents = SimpleDirectoryReader(image_directory_path).load_data()\n",
    "        for doc in image_documents:\n",
    "            yolo_responses: List[Results] = yolo_model.predict(doc.image_path, classes=[0, 1, 2, 3, 4, 6])\n",
    "            if yolo_responses and len(yolo_responses) > 0:\n",
    "                yolo_response = yolo_responses[0]\n",
    "                detected_objects = []\n",
    "                if yolo_response.boxes is not None:\n",
    "                    detected_objects.append([yolo_model.names[int(c)] for c in yolo_response.boxes.cls])\n",
    "                    doc.metadata = {os.path.split(doc.image_path)[1]: detected_objects}\n",
    "        final_response = [image.metadata for image in image_documents]\n",
    "        return final_response\n",
    "\n",
    "    analyse_image_ppe_violation = FunctionTool.from_defaults(fn=analyse_image_ppe_violation)\n",
    "    agent = FunctionAgent(\n",
    "        tools=[analyse_image_ppe_violation],\n",
    "        llm=llm,\n",
    "        description=\"A computer vision model detects PPE compliance in real-time, with results logged to a JSON file.Generate report based on the same\"\n",
    "    )\n",
    "    response: AgentOutput = await agent.run(user_msg=\"Provide ppe report\")\n",
    "    print(response.response.content)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    asyncio_run(main())"
   ],
   "id": "3c80d5cf9e044ac9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 18:37:21,679 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/venugopalgotagi/PycharmProjects/llamaindex_poc/test/1.png: 640x512 1 helmet, 2 Persons, 41.4ms\n",
      "Speed: 3.2ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "image 1/1 /Users/venugopalgotagi/PycharmProjects/llamaindex_poc/test/2.png: 256x640 7 helmets, 7 vests, 8 Persons, 16.0ms\n",
      "Speed: 0.8ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "image 1/1 /Users/venugopalgotagi/PycharmProjects/llamaindex_poc/test/3.png: 640x640 1 helmet, 1 vest, 1 Person, 36.8ms\n",
      "Speed: 1.2ms preprocess, 36.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/venugopalgotagi/PycharmProjects/llamaindex_poc/test/4.png: 544x640 3 helmets, 3 vests, 3 Persons, 25.5ms\n",
      "Speed: 1.3ms preprocess, 25.5ms inference, 0.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 /Users/venugopalgotagi/PycharmProjects/llamaindex_poc/test/5.png: 416x640 1 Person, 20.8ms\n",
      "Speed: 0.8ms preprocess, 20.8ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /Users/venugopalgotagi/PycharmProjects/llamaindex_poc/test/6.png: 640x576 1 helmet, 1 Person, 28.4ms\n",
      "Speed: 1.5ms preprocess, 28.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 576)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 18:37:23,120 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the PPE (Personal Protective Equipment) report, it appears that:\n",
      "\n",
      "* In image 1, there is 1 person wearing a helmet.\n",
      "* In image 2, there are multiple people wearing helmets and vests. \n",
      "* In image 3, there is 1 person wearing a vest and a helmet.\n",
      "* In image 4, most of the people are wearing helmets.\n",
      "* In image 5, there is no one wearing any PPE.\n",
      "* In image 6, there is 1 person wearing a helmet.\n",
      "\n",
      "It's difficult to determine if all workers are following proper safety protocols based on this report alone.\n"
     ]
    }
   ],
   "execution_count": 402
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
